# 面试官：说说你了解几种限流算法，手写个demo?

在高并发以及分布式的场景下，接口限流是保护系统稳定性的核心手段。当瞬时流量激增时，合理的限流策略可以避免服务器过载、数据库雪崩等问题。本文将深入解析6种主流限流算法，并提供具体的实现思路，同时也会提供分布式限流的一些思路。
# 一、接口限流
## 1.1 接口限流的必要性
核心作用：防止突发流量导致系统雪崩，保障核心业务可用性。典型应用场景：

- 秒杀活动的库存查询接口
- 第三方API调用频率限制
- 敏感操作防重放攻击

另外也可以防止恶意爬虫以及恶意攻击
## 1.2 什么是限流
限流是对某一时间窗口内的请求数进行限制，保持系统的可用性和稳定性，防止因流量暴增而导致的系统运行缓慢或宕机。

在高并发系统中，出于系统保护角度考虑，通常会对流量进行限流。

在分布式系统中，高并发场景下，为了防止系统因突然的流量激增而导致的崩溃，同时保证服务的高可用性和稳定性，限流是最常用的手段。

# 二、接口限流算法
## 2.1 固定窗口算法
固定窗口算法又称计数器算法、Fixed Window算法，是最简单的限流算法。
### 2.1.1 原理
其原理如下，在指定的固定时间窗口内统计请求次数，超过阈值则拒绝请求。当进入下一个时间周期时进行访问次数的清零。如图所示，我们要求3秒内的请求不要超过150次：

![image](https://github.com/user-attachments/assets/d75a342f-020b-4f40-83e1-80585cc61029)
### 2.1.2 代码实现
最常用的实现就是使用计数器的方式实现                      
以下是单机版版Java代码实现
```java
public class FixedWindowRateLimiter {
    private final long windowSize = 3000; //时间窗口大小，单位毫秒
    private final int maxRequestCount = 150; // 允许通过的请求数
    private final AtomicInteger counter = new AtomicInteger(0); // 当前窗口通过的请求数，AtomicInteger保证线程安全
    private volatile long windowBorder;//窗口右边界

    public boolean tryAcquire() {
        long currentTime = System.currentTimeMillis();
        if (currentTime > windowBorder) { //如果当前时间大于时间窗口的右边界,就一直将窗口的右边界平移
            synchronized (this) { //加锁保证只有一个线程对时间窗口计算，并根据volatile的可见性将windowBorder对其他线程可见
                long now = System.currentTimeMillis(); // 双重检查，避免线程阻塞时currentTime变化产生的影响
                do {
                    windowBorder += windowSize;
                    counter.set(0); // 重置计数器
                } while (now > windowBorder);
            }
        }
        return counter.incrementAndGet() <= maxRequestCount; //判断当前窗口期内的请求数量是否超出限制并对请求数+1
    }
}
```
计数器法，非常简单粗暴，以上demo只是单机式限流。下面说一下分布式情况下的思路

如果需要进行分布式限流，可以使用Redis。
1. 当请求过来时以接口名称作为key，获取自增后的value，
2. 如果value为1，即key不存在，创建了新的则设置``windowSize``作为key过期时间。
3. 如果key存在，则再判断value是否大于``maxRequestCount``。大于``maxRequestCount``则进行限流，否则允许请求通过。
```lua
-- KEYS[1]限流键名，ARGV[1]限流阈值，ARGV[2]时间窗口（秒）
local key = KEYS[1]
local maxRequestCount = tonumber(ARGV[1])
local windowSize = tonumber(ARGV[2])
 
-- 当前计数自增 
local current = redis.call('INCR',  key)
if current == 1 then 
    redis.call('EXPIRE',  key, windowSize) -- 首次设置过期时间 
end 
 
-- 判断是否超限 
if current > maxRequestCount then 
    return 0 -- 限流 
else 
    return 1 -- 放行 
end 
```
### 2.1.3 具体实现的工具类
Guava的LoadingCache、Resilience4j、Bucket4j
### 2.1.4 优缺点
优点：
- 实现简单，容易理解

缺点：
- 限流不够平滑。例如：限流是每秒3个，在第一毫秒发送了3个请求，达到限流，窗口剩余时间的请求都将会被拒绝，体验不好，这种现象叫做“突刺现象”。
- 
- 因为是在某个时间窗口内进行流量控制，所以可能会出现窗口边界效应，即在时间窗口的边界处可能会有大量的请求被允许通过，从而导致突发流量。即：如果第2到3秒内产生了150次请求，而第3到4秒内产生了150次请求，那么其实在第2秒到第4秒这两秒内，就已经发生了300次请求了，远远大于我们要求的3秒内的请求不要超过150次这个限制，如下图所示

![image](https://github.com/user-attachments/assets/6a5a8791-4929-41c8-9247-27de909491f7)

## 2.2 滑动窗口算法
滑动窗口法可以解决固定窗口法下在窗口切换时会受到两倍于阈值数量的请求的问题。

在滑动窗口算法中，窗口的起止时间是动态的，窗口的大小固定。这种算法能够较好地处理窗口边界问题，但是实现相对复杂，需要记录每个请求的时间戳。
### 实现原理
滑动窗口在固定窗口的基础上，将一个窗口分为若干个等份的小窗口，每次仅滑动一小块的时间。每个小窗口对应不同的时间点，拥有独立的计数器，当请求的时间点大于当前窗口的最大时间点时，则将窗口向前平移一个小窗口（将第一个小窗口的数据舍弃，第二个小窗口变成第一个小窗口，当前请求放在最后一个小窗口），整个窗口的所有请求数相加不能大于阈值。其中，Sentinel就是采用滑动窗口算法来实现限流的。如图所示：

![image](https://github.com/user-attachments/assets/8238d78e-97c5-4150-90cc-539b6f5924f3)

核心步骤：
1. 把3秒钟划分为3个小窗，每个小窗限制请求不能超过50秒。
2. 比如我们设置，3秒内不能超过150个请求，那么这个窗口就可以容纳3个小窗，并且随着时间推移，往前滑动。每次请求过来后，都要统计滑动窗口内所有小窗的请求总量。
### 代码实现
以下是单机版版Java代码实现计数器方法：
```java
public class SlidingWindowRateLimiter {

    long windowSize; //时间窗口大小，单位毫秒
    int shardNum;//分片窗口数
    int maxRequestCount;//允许通过的请求数
    int[] shardRequestCount; //各个窗口内请求计数
    int totalCount;//请求总数
    int shardId;//当前窗口下标
    long tinyWindowSize;//每个小窗口大小，毫秒
    long windowBorder;//窗口右边界

    public synchronized boolean tryAcquire() {
        long currentTime = System.currentTimeMillis();
        if (windowBorder < currentTime) {
            do {
                shardId = (++shardId) % shardNum;
                totalCount -= shardRequestCount[shardId];
                shardRequestCount[shardId] = 0;
                windowBorder += tinyWindowSize;
            } while (windowBorder < currentTime);
        }
        if (totalCount < maxRequestCount) {
            shardRequestCount[shardId]++;
            totalCount++;
            return true;
        } else {
            return false;
        }
    }
}
```
另一种变形的写法,通过维护一个时间戳队列，当新请求到达时移除超出时间窗口的旧记录，统计当前窗口内请求数
```java
public class SlidingWindowRateLimiter {
    private final int maxRequests; // 窗口内最大请求数 
    private final long windowMillis; // 时间窗口长度（毫秒）
    private final Queue<Long> timeStamps = new ConcurrentLinkedQueue<>(); // 请求时间戳队列 
 
    public SlidingWindowRateLimiter(int maxRequests, long windowSeconds) {
        this.maxRequests  = maxRequests;
        this.windowMillis  = windowSeconds * 1000;
    }
 
    /**
     * 判断是否允许新请求 
     */
    public synchronized boolean allowRequest() {
        long currentTime = System.currentTimeMillis(); 
        // 移除窗口之外的过期记录（时间戳早于当前窗口起点）
        while (!timeStamps.isEmpty()  &&  (currentTime - timeStamps.peek()  > windowMillis)) { //peek查看头结点元素
            timeStamps.poll();  //poll删除头结点，为空返回null，不抛出异常
        }
        
        // 判断当前窗口内请求数 
        if (timeStamps.size()  < maxRequests) {
            timeStamps.offer(currentTime); 
            return true;
        }
        return false;
    }
}
```

分布式仍使用redis的ZSet以及lua脚本实现,具体步骤为：
1. 请求进入时，先通过zcount命令统计分数为``currentTime-windowTime``到``currentTime``的数量``count``，即当前时间向前时间窗口内的请求数量
2. 如果``count``大于等于``limitCount``则进行限流，否则允许请求通过。
3. 记录当前请求时间戳set到``key``中,并且设置过期时间
```lua
-- KEYS[1]限流键名，ARGV[1]窗口时间（毫秒），ARGV[2]限流阈值 
local key = KEYS[1]
local windowTime = tonumber(ARGV[1])
local limitCount = tonumber(ARGV[2])
local currentTime = tonumber(redis.call('TIME')[1])  * 1000 -- 当前毫秒时间戳,获取服务器时间，避免客户端时间不同步问题 
 
-- 清理窗口外数据 
redis.call('ZREMRANGEBYSCORE',  key, 0, currentTime - windowTime)
 
-- 统计当前窗口内请求数 
local count = redis.call('ZCOUNT',  key, currentTime - windowTime, currentTime)
 
if count >= limitCount then 
    return 0 -- 限流 
else 
    -- 记录当前请求时间戳 
    redis.call('ZADD',  key, currentTime, currentTime)
    redis.call('PEXPIRE',  key, windowTime)  -- 设置过期时间,单位毫秒
    return 1 -- 放行 
end 
```
### 具体实现的工具类
Resilience4j、
### 优缺点
优点：解决了固定窗口算法的边界效应问题,避免了突发流量压垮服务器
缺点: 
- 仍然存在限流不够平滑的问题。
- 另外在处理时会需要记录时间和各个小窗口内的请求计数，会造成一定的内存和时间开销
## 2.3 漏桶算法
漏桶算法(Leaky Bucket)是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它可以有效地控制数据的传输速率以及防止网络拥塞。

### 实现原理
漏桶是一个很形象的比喻，外部请求就像是水一样不断注入水桶中，而水桶已经设置好了最大出水速率，漏桶会以这个速率匀速放行请求，而当水超过桶的最大容量后则被丢弃。不管上面的水流速度有多块，漏桶水滴的流出速度始终保持不变。消息中间件就采用的漏桶限流的思想。如图所示：
![013b72f5-8556-4851-a89a-a33f15ec68d5](https://github.com/user-attachments/assets/451315dd-375a-420e-af85-55d2f27a359e)

核心步骤：
a.一个固定容量的漏桶，按照固定速率出水（处理请求）；
b.当流入水（请求数量）的速度过大会直接溢出（请求数量超过限制则直接拒绝）。
c.桶里的水（请求）不够则无法出水（桶内没有请求则不处理）。
### 代码实现
```java
public class LeakyBucketRateLimiter {
    int capacity; //桶的容量
    AtomicInteger water = new AtomicInteger();//桶中现存水量
    long leakTimestamp; //开始漏水时间
    int leakRate; //水流出的速率，即每秒允许通过的请求数

    public LeakyBucketRateLimiter(int capacity, int leakRate) {
        this.capacity = capacity;
        this.leakRate = leakRate;
    }

    public synchronized boolean tryAcquire() {
        //桶中没有水， 重新开始计算
        if (water.get() == 0) {
            leakTimestamp = System.currentTimeMillis();
            water.incrementAndGet();
            return water.get() < capacity;
        }
        //先漏水，计算剩余水量
        long currentTime = System.currentTimeMillis();
        int leakedWater = (int) ((currentTime - leakTimestamp) / 1000 * leakRate);
        //可能时间不足，则先不漏水
        if (leakedWater != 0) {
            int leftWater = water.get() - leakedWater;
            //可能水已漏光。设为0
            water.set(Math.max(0, leftWater));
            leakTimestamp = System.currentTimeMillis();
        }
        if (water.get() < capacity) {
            water.incrementAndGet();
            return true;
        } else {
            return false;
        }
    }
}
```

使用Redis的Hash结构实现分布式限流，具体步骤如下：
1. 请求进入时，先获取hash的值，判断key对应的value是否存在，不存在则为首次请求,则水量``currentWater``为0, ``lastLeakTime``为之前的记录的漏水时间。存在则为后续请求，并从Hash中获取当前的水量``currentWater``和最后一次漏水时间``lastLeakTime``
2. 先计算漏水量，根据``currentTime - lastLeakTime``计算当前时间和上次漏水的时间差，再根据速率相乘计算
3. 对是否限流判断，根据``currentWater + 1 > capacity``判断，为true则拒绝请求，为false则放行并执行下一步
4. 更新水量和漏水时间
```Lua
-- KEYS[1]：限流键名 
local key = KEYS[1]
local capacity = tonumber(ARGV[1])  -- 桶容量 
local leakRate = tonumber(ARGV[2])  -- 漏水速率（单位：请求/秒）
 
-- 获取当前桶状态 
local bucket = redis.call('HGETALL',  key) 
local currentTime = redis.call('TIME')[1] -- 获取服务器时间，避免客户端时间不同步问题
local currentWater = 0 
local lastLeakTime = currentTime 
 
-- 解析Hash数据 
if #bucket > 0 then 
    currentWater = tonumber(bucket[2])
    lastLeakTime = tonumber(bucket[4])
end 
 
-- 计算漏水量（距离上次漏水的时间差*速率）
local elapsed = currentTime - lastLeakTime 
local leakedWater = math.floor(elapsed  * leakRate)
currentWater = math.max(0,  currentWater - leakedWater)
 
-- 判断是否允许新请求 
if currentWater >= capacity then 
    return 0  -- 限流 
else 
    -- 更新水位和时间戳 
    redis.call('HMSET',  key, 'water', currentWater+1, 'lastLeak', currentTime)
    redis.call('EXPIRE',  key, 60)  -- 设置键过期时间 
    return 1  -- 放行 
end 
```
### 具体实现的工具类
Python的leaky-bucket
### 优缺点
**优点：**
1. 平滑流量。由于漏桶算法以固定的速率处理请求，可以有效地平滑和整形流量，避免流量的突发和波动（类似于消息队列的削峰填谷的作用）。
2. 防止过载。当流入的请求超过桶的容量时，可以直接丢弃请求，防止系统过载。

**缺点：**
1. 无法处理突发流量：由于漏桶的出口速度是固定的，无法处理突发流量。例如，即使在流量较小的时候，也无法以更快的速度处理请求。
2. 可能会丢失数据：如果入口流量过大，超过了桶的容量，那么就需要丢弃部分请求。在一些不能接受丢失请求的场景中，这可能是一个问题。
3. 不适合速率变化大的场景：如果速率变化大，或者需要动态调整速率，那么漏桶算法就无法满足需求。
4. 资源利用率：不管当前系统的负载压力如何，所有请求都得进行排队，即使此时服务器的负载处于相对空闲的状态，这样会造成系统资源的浪费。﻿
由于漏桶的缺陷比较明显，所以在实际业务场景中，使用的比较少。
## 2.4 令牌桶算法
令牌桶算法是基于漏桶算法的一种改进，主要在于令牌桶算法能够在限制服务调用的平均速率的同时，还能够允许一定程度内的突发调用。

令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。从原理上看，令牌桶算法和漏桶算法是相反的，一个“进水”，一个是“漏水”。
### 实现原理
1. 系统以固定的速率向桶中添加令牌；
2. 当有请求到来时，会尝试从桶中移除一个令牌，如果桶中有足够的令牌，则请求可以被处理或数据包可以被发送；
3. 如果桶中没有令牌，那么请求将被拒绝；
4. 桶中的令牌数不能超过桶的容量，如果新生成的令牌超过了桶的容量，那么新的令牌会被丢弃。
5. 令牌桶算法的一个重要特性是，它能够应对突发流量。当桶中有足够的令牌时，可以一次性处理多个请求，这对于需要处理突发流量的应用场景非常有用。但是又不会无限制的增加处理速率导致压垮服务器，因为桶内令牌数量是有限制的。

如图所示：
![image](https://github.com/user-attachments/assets/92c4e367-db48-4c50-991c-4f2a729882fc)
### 代码实现
```java
public class TokenBucketRateLimiter { 
    int capacity; // 桶的容量，即令牌桶最多能容纳的令牌数 
    AtomicInteger tokens = new AtomicInteger(); // 桶中现存令牌数 
    long lastRefillTimestamp; // 上次添加令牌的时间 
    int refillRate; // 令牌添加的速率，即每秒向桶中添加的令牌数 
 
    public TokenBucketRateLimiter(int capacity, int refillRate) { 
        this.capacity  = capacity; 
        this.refillRate  = refillRate; 
        this.tokens.set(capacity);  // 初始化时，桶中令牌数为满 
        this.lastRefillTimestamp  = System.currentTimeMillis();  
    } 
 
    public synchronized boolean tryAcquire() { 
        // 先添加令牌 
        long currentTime = System.currentTimeMillis();  
        int newTokens = (int) ((currentTime - lastRefillTimestamp) / 1000 * refillRate); 
        if (newTokens > 0) { 
            // 计算添加新令牌后的令牌数，但不能超过桶的容量 
            int newTokenCount = Math.min(capacity,  tokens.get()  + newTokens); 
            tokens.set(newTokenCount);  
            lastRefillTimestamp = currentTime; 
        } 
 
        // 尝试获取令牌 
        if (tokens.get()  > 0) { 
            tokens.decrementAndGet();  
            return true; 
        } else { 
            return false; 
        } 
    }
} 
```
看的出来，令牌桶和漏桶的原理有些相似。
漏桶是以一个恒定速率的出水，即处理请求的速率是恒定的。而令牌桶则是以一个恒定的速率往桶中放入令牌，在桶中令牌用完之前，并不限制处理请求的速率。
令牌桶的一个优势在于，可以允许短时间内的一次突发流量。但不会允许在短时间内的多次突发流量，因为令牌的填充也是需要时间的。

使用Redis的Hash结构实现分布式限流，具体步骤如下：
1. 请求进入时，先获取hash的值，判断key对应的value是否存在，不存在则为首次请求,则令牌数``tokens``设为满容量``capacity``, ``lastRefillTime``为最后一次装令牌记录的时间。存在则为后续请求，并从Hash中获取当前的令牌``tokens``和最后一次填充时间``lastRefillTime``
2. 先计算新增令牌量，根据``currentTime - lastRefillTime``计算当前时间和上次填充的时间差，再根据速率相乘计算
3. 对是否限流判断，根据``tokens >= 1``判断，为false则拒绝请求，为true则放行并执行下一步
4. 更新令牌``token - 1``和填充时间

```lua
-- KEYS[1]：限流键名 
local key = KEYS[1]
local capacity = tonumber(ARGV[1])  -- 桶容量 
local refillRate = tonumber(ARGV[2])  -- 令牌生成速率（单位：令牌/秒）
 
-- 获取当前桶状态 
local bucket = redis.call('HGETALL',  key)
local currentTime = redis.call('TIME')[1] -- 获取服务器时间，避免客户端时间不同步问题
local tokens = capacity 
local lastRefillTime = currentTime 
 
-- 解析Hash数据 
if #bucket > 0 then 
    tokens = tonumber(bucket[2])
    lastRefillTime = tonumber(bucket[4])
end 
 
-- 计算新增令牌（距离上次填充的时间差*速率）
local elapsed = currentTime - lastRefillTime 
local newTokens = math.floor(elapsed  * refillRate)
tokens = math.min(capacity,  tokens + newTokens)
 
-- 判断是否允许请求 
if tokens >= 1 then 
    tokens = tokens - 1 
    redis.call('HMSET',  key, 'tokens', tokens, 'lastRefill', currentTime)
    redis.call('EXPIRE',  key, 60)  -- 设置键过期时间 
    return 1  -- 放行 
else 
    return 0  -- 限流 
end 
```
### 具体实现的工具类
Guava的RateLimiter
### 优缺点
优点：
1. 可以处理突发流量：令牌桶算法可以处理突发流量。当桶满时，能够以最大速度处理请求。这对于需要处理突发流量的应用场景非常有用。
2. 限制平均速率：在长期运行中，数据的传输率会被限制在预定义的平均速率（即生成令牌的速率）。
3. 灵活性：与漏桶算法相比，令牌桶算法提供了更大的灵活性。例如，可以动态地调整生成令牌的速率。
缺点：
1. 可能导致过载：如果令牌产生的速度过快，可能会导致大量的突发流量，这可能会使网络或服务过载。
2. 需要存储空间：令牌桶需要一定的存储空间来保存令牌，可能会导致内存资源的浪费。
3. 实现稍复杂：相比于计数器算法，令牌桶算法的实现稍微复杂一些。

# 总结
以上就是常见的四种限流方法，但是在实践中，接口的限流不指局限于部署的应用，同样的我们也会使用到例如通过nginx来进行一个接入层的限流，和一个分布式的限流，这些限流的思想大致也都是上述的四种方法。通过合理选择限流算法，可以在保障系统稳定性的同时最大化资源利用率。建议结合具体业务场景进行组合使用，例如网关层使用滑动窗口算法，核心服务采用令牌桶+自适应限流策略
